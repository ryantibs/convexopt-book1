\chapter{Duality}
\label{chap:duality}

\section{LP duality*}
\label{sec:lp_duality}

Duality is fascinating topic in mathematical optimization: the basic arguments
used in the theory of duality are elementary, and yet they can lead to powerful
and far-reaching conclusions.    

The story begins, for us, with linear programs (LPs). Consider a generic LP of
the form 
\begin{equation}
\label{eq:lp_primal}
\begin{alignedat}{2}
&\minimize_x \quad && c^\T x \\
&\st && Ax \leq b \\
& && Gx = h, 
\end{alignedat}
\end{equation}
where $c \in \R^d$, $A \in \R^{m \times d}$, $b \in \R^m$, $G \in \R^{k \times 
  d}$, $h \in \R^k$. The reason we start the chapter by studying LPs is that,   
in this problem class, we can build up dual problems ``constructively''; this 
constructive approach is not possible for general optimization problems, and
helps us appreciate the importance and elegance of Lagrange duality, which is
covered next.     

The fundamental question that underlies the study of duality is as follows: what
is the tightest lower bound we can form on the optimal criterion value $f^\star
= c^\T x^\star$ in \eqref{eq:lp_primal}? To address this, suppose that $u \in
\R^m$ and $v \in \R^k$ are arbitrary vectors---which we call \emph{dual 
  variables} in this context---with $u$ nonnegative in each component, $u \geq   
0$. Provided that $x \in \R^d$ is feasible for problem \eqref{eq:lp_primal}, it
holds that $u^\T (Ax - b) \leq 0$ and $v^\T (Gx - h) = 0$, and so, adding these
together gives        
\begin{equation}
\label{eq:lp_dual_nonnegativity}
u^\T (Ax - b) + v^\T (Gx - h) \leq 0.
\end{equation}
In order to obtain a lower bound on the criterion value $c^\T x$, we rearrange
the above into
\[
(-A^\T u - G^\T v)^\T x \geq -b^\T u - h^\T v.
\]
The key observation is that this provides the lower bound we desire provided
that the dual variables $u,v$ are chosen such that $-A^\T u - G^\T v= c$. This
is true for any feasible $x$, thus taking an infimum over all such $x$ gives   
\[
f^\star \geq -b^\T u - h^\T v, \quad \text{for any $u,v$ such that $-A^\T u -
  G^\T v = c$ and $u \geq 0$}.
\]
Finally, to make this lower bound as tight as possible, we maximize the
right-hand side above,  
\begin{equation}
\label{eq:lp_weak_duality}
f^\star \geq \sup \big\{ -b^\T u - h^\T v :  A^\T u + G^\T v = -c, \, u \geq 0
\big\}.
\end{equation}
Now, the right-hand side in \eqref{eq:lp_weak_duality}, which we may denote as 
$g^\star = -b^\T u^\star - h^\T v^\star$, is itself the optimal criterion value
associated with an optimization problem, indeed an LP,     
\index{dual problem!linear program}
\begin{equation}
\label{eq:lp_dual}
\begin{alignedat}{2}
&\maximize_{u,v} \quad && b^\T u - h^\T v \\
&\st && A^\T u + G^\T v = -c \\
& && u \geq 0.
\end{alignedat}
\end{equation}
In this context, we call \eqref{eq:lp_dual} the \emph{dual LP} and the original 
problem \eqref{eq:lp_primal} the \emph{primal LP}. Note that, by construction 
\eqref{eq:lp_weak_duality}, we have $f^\star \geq g^\star$: the optimal
criterion in the dual problem is a lower bound on the optimal criterion in the  
primal problem.  

There are several natural follow-up questions that we can ask: for example, when
does equality hold in \eqref{eq:lp_weak_duality}, $f^\star = g^\star$? And how
can we relate solutions $x^\star$ and $u^\star, v^\star$ in \eqref{eq:lp_primal}
and \eqref{eq:lp_dual}, respectively (beyond the optimal criterion values)? We
will address these questions and more, over this chapter and the next
one. First, however, we must develop a theory of duality beyond LPs.

The attempt to move beyond linear programs exposes a shortcoming of the above 
approach: if the criterion $f$ is nonlinear, but the constraint functions are
linear, then we have no way in general to manipulate the constraints---a set of  
linear equalities and inequalities in $x$---to construct a lower bound on
$f(x)$. But there is another way: Lagrange duality, as we will see next, applies
not only to LPs but to optimization problems broadly (even some nonconvex ones).    

\section{Lagrangian duality}
\label{sec:lagrangian_duality}

Lagrangian duality (or Lagrange duality) starts with the same motivation as in
the last section, but now cast in a more general setting: we seek a lower bound
on the optimal criterion value $f^\star$ in          
\begin{equation}
\label{eq:primal_problem}
\begin{alignedat}{2}
&\minimize_x \quad && f(x) \\
&\st \quad && h_i(x) \leq 0, \; i=1,\ldots,m \\ 
& && \ell_j(x) = 0, \; j=1,\ldots,k.
\end{alignedat}
\end{equation}
At the moment, we do not assume that criterion $f$ or the constraint functions
$h_i$, $i=1,\dots,m$, and $\ell_j$, $j=1,\dots,k$ are convex. Thus, to be clear,
we do not assume that \eqref{eq:primal_problem} is a convex problem. 

As before, let $u \in \R^m$ and $v \in \R^k$ be arbitrary vectors, with $u \geq
0$, which we call \emph{dual variables} in the current context. Using the same
basic idea as in \eqref{eq:lp_dual_nonnegativity}, observe that for any $x$ that
is feasible for problem \eqref{eq:primal_problem},
\[
\sum_{i=1}^m u_i h_i(x) + \sum_{j=1}^r v_j \ell_j(x) \leq 0.
\]
We now add this quantity to the criterion $f(x)$ to define what we call the
\emph{Lagrangian function},   
\index{Lagrangian function}
\[
L(x,u,v) = f(x) + \sum_{i=1}^m u_i h_i(x) + \sum_{j=1}^r v_j \ell_j(x).
\] 
By construction, this provides a lower bound on the criterion,
\[
f(x) \geq L(x,u,v), \quad \text{for any feasible $x$ and $u,v$ such that $u
  \geq 0$}.
\]
Minimizing over all $x$ in the feasible set, which we denote as $C \subseteq
\R^d$, yields 
\[
f^\star \geq \inf_{x \in C} \, L(x,u,v) \geq \inf_{x \in \R^d} \, L(x,u,v),
\quad \text{for any $u,v$ such that $u \geq 0$}. 
\]
The second inequality above is really the key idea behind Lagrange duality; had
we stopped at the first inequality, we would have not have (yet) gotten anywhere 
practically interesting. Minimizing the Lagrangian over $x \in C$ can be
hard---in general, it is no easier than minimizing $f$ over $x \in C$, which 
is our original primal problem \eqref{eq:primal_problem}. Meanwhile, minimizing
the Lagrangian over $x \in \R^d$ is often more tractable (as we will see in
examples that follow),  


While this gives us a lower bound on $f^\star$, we have not (yet) gotten
anywhere practically interesting. Minimizing the Lagrangian over $x \in C$ is
hard, in general---it is no easier than minimizing $f$ over $x \in C$, which 
is our original primal problem \eqref{eq:primal_problem}. Next comes the simple
but critical insight in Lagrange duality: \emph{we can instead minimize the
  Lagrangian over all $x \in \R^d$}. This still gives a lower bound on the
optimal criterion value (since it can only make the right-hand side above
smaller). We hence define the \emph{Lagrange dual function} by      
\begin{equation}
\label{eq:dual_function}
g(u,v) = \inf_{x \in \R^d} \, L(x,u,v), \quad \text{for any $u,v$ such that $u
  \geq 0$},
\end{equation}
which by construction satisfies
\[
f^\star \geq g(u,v), \quad \text{for any $u,v$ such that $u \geq 0$}. 
\]

\begin{Example}
LPs.
\end{Example}

\section{Interpretations}
\label{sec:duality_interpretations}

\section{SDP duality*}
\label{sec:sdp_duality}

% for SDP duality: take a look at 
% https://www.mit.edu/~parrilo/cdc03_workshop/ejc03_comp.pdf
% https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-251j-introduction-to-mathematical-programming-fall-2009/readings/MIT6_251JF09_SDP.pdf